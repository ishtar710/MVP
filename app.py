import streamlit as st
import json, requests, re
from typing import List, Dict, Any
from openai import AzureOpenAI
from dotenv import load_dotenv
import os
import plantuml

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_DEPLOYMENT_MODEL = os.getenv("AZURE_DEPLOYMENT_MODEL")

# Azure Search ì„¤ì •
SEARCH_ENDPOINT = os.getenv("SEARCH_ENDPOINT")
SEARCH_API_KEY = os.getenv("SEARCH_API_KEY")
SEARCH_INDEX = os.getenv("SEARCH_INDEX")


# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” 
try:
    # Initialize the OpenAI client
    openai_client = AzureOpenAI(
        api_version="2024-12-01-preview",
        api_key=AZURE_OPENAI_API_KEY,
        azure_endpoint=AZURE_OPENAI_ENDPOINT
    )
except Exception as e:
    st.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    st.stop()

# í•¨ìˆ˜: Parse í”„ë¡¬í”„íŠ¸ ìƒì„±
def build_parse_prompt(trace_logs: List[Dict[str, Any]]) -> List[Dict[str, str]]:
    """
    LLM Parse ë‹¨ê³„ì— ë„£ì„ í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ ìƒì„±
    - ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ë„ë¡ ì§€ì‹œ
    """
    return [
        {
            "role": "system",
            "content": (
                "ë‹¹ì‹ ì€ PICASO ë¡œê·¸ë¥¼ ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨ stepìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë¶„ì„ê¸°ì…ë‹ˆë‹¤.\n"
                "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•´ì•¼ í•˜ë©°, ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n"
                "JSON ì´ì™¸ì˜ í…ìŠ¤íŠ¸(ì˜ˆ: ì„¤ëª…, ì£¼ì„)ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ``` ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì½”ë“œ ë¸”ë¡ë„ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤."
            )
        },
        {
            "role": "user",
            "content": f"""
ì•„ë˜ëŠ” ë™ì¼ transactionIdì— ì†í•˜ëŠ” ë¡œê·¸ í•­ëª©ë“¤ì…ë‹ˆë‹¤.
ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ IN-REQ â†’ OUT-REQ â†’ OUT-RES â†’ IN-RES stepì„ ì¶”ë¡ í•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì‹œì˜¤.

ê·œì¹™:
1. ê° íŠ¸ëœì­ì…˜ì€ ë°˜ë“œì‹œ IN-REQ â†’ OUT-REQ â†’ OUT-RES â†’ IN-RES ìˆœì„œë¡œ êµ¬ì„±ëœë‹¤.
   - IN-REQ/IN-RESëŠ” ê°ê° í•˜ë‚˜ë§Œ ì¡´ì¬í•œë‹¤.
   - OUT-REQ/OUT-RESëŠ” ì—¬ëŸ¬ ê°œ ì¡´ì¬í•  ìˆ˜ ìˆë‹¤.
   - ì¤‘ê°„ stepì´ ëˆ„ë½ë  ìˆ˜ ìˆìœ¼ë©°, ì´ ê²½ìš° "MISSING" stepìœ¼ë¡œ ì±„ìš´ë‹¤.

2. ë¡œê·¸ì—ëŠ” REQê°€ ê¸°ë¡ë˜ì§€ ì•Šê³  RES ë¡œê·¸ë§Œ ë‚¨ëŠ”ë‹¤.
   - logType=IN_RES â†’ IN-REQ + IN-RESë¥¼ ì¶”ë¡ í•´ì•¼ í•œë‹¤.
   - logType=OUT_RES â†’ OUT-REQ + OUT-RESë¥¼ ì¶”ë¡ í•´ì•¼ í•œë‹¤.

3. ë§¤í•‘ ê·œì¹™:
   - IN-REQì˜ actorëŠ” caller(ì™¸ë¶€ ì‹œìŠ¤í…œ), targetì€ PICASO.
   - OUT-REQì˜ actorëŠ” PICASO, targetì€ OUT-RESì˜ destination.
   - OUT-RESì˜ actorëŠ” OUT-REQì˜ target(ì¦‰, ì™¸ë¶€ ì‹œìŠ¤í…œ), targetì€ PICASO.
   - IN-RESì˜ actorëŠ” PICASO, targetì€ IN-REQì˜ actor(ì¦‰, caller).
   - caller ì •ë³´ëŠ” ìµœì´ˆ ìš”ì²­(IN-REQ)ë¶€í„° IN-RESê¹Œì§€ ë™ì¼í•˜ê²Œ ì—°ê²°ëœë‹¤.
   - IN-RESì˜ destinationê³¼ OUT-REQì˜ í˜¸ì¶œìëŠ” í•­ìƒ PICASOë¡œ ê³ ì •í•œë‹¤.

4. statusì™€ latency_ms:
   - statusëŠ” response.codeë¥¼ ì‚¬ìš©í•œë‹¤. ì—†ìœ¼ë©´ response.typeìœ¼ë¡œ ìœ ì¶”(Eâ†’500, Iâ†’200).
   - latency_msëŠ” response.durationì„ ì •ìˆ˜ë¡œ ë³€í™˜í•œë‹¤. ì—†ìœ¼ë©´ -1.

ì¶œë ¥ ìŠ¤í‚¤ë§ˆ:
{{
  "trace_id": "íŠ¸ëœì­ì…˜ID",
  "steps": [
    {{
      "step_no": 1,
      "type": "IN-REQ",
      "actor": "...",
      "action": "...",
      "target": "...",
      "status": "...",
      "latency_ms": 123
    }},
    ...
  ]
}}

ì…ë ¥ ë¡œê·¸:
{json.dumps(trace_logs, ensure_ascii=False, indent=2)}
"""
        }
    ]


def get_embedding(text):
    url = f"{AZURE_OPENAI_ENDPOINT}openai/deployments/dev-text-embedding-ada-002/embeddings?api-version=2023-05-15"
    headers = {
        "api-key": AZURE_OPENAI_API_KEY,
        "Content-Type": "application/json"
    }
    body = {
        "input": text
    }
    # print("==== get_embedding í˜¸ì¶œ ====")
    # print(url, headers, body)
    response = requests.post(url, headers=headers, json=body)
    # print("==== get_embedding ì‘ë‹µ ====")
    # print(response.text)
    response.raise_for_status()
    return response.json()["data"][0]["embedding"]

def search_description_by_embedding(embedding):
    url = f"{SEARCH_ENDPOINT}/indexes/{SEARCH_INDEX}/docs/search?api-version=2023-10-01-Preview"
    headers = {
        "api-key": SEARCH_API_KEY,
        "Content-Type": "application/json"
    }
    body = {
        "vectorQueries": [
            {
                "kind": "vector",
                "vector": embedding,
                "fields": "text_vector",
                "k": 1
            }
        ],
        "select": "chunk,title"
    }
    # print("==== search_description_by_embedding í˜¸ì¶œ ====")
    # print(url, headers, body)
    response = requests.post(url, headers=headers, json=body)
    # print("==== search_description_by_embedding ì‘ë‹µ ====")
    # print(response.text)
    response.raise_for_status()
    # print("==== search_description_by_embedding ì™„ë£Œ ====")
    results = response.json()["value"]
    if results:
        return results[0]["chunk"]
    return "ì„¤ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def summarize_description(text):
    if not text or len(text) < 30:
        return text  # ì§§ì€ ì„¤ëª…ì€ ê·¸ëŒ€ë¡œ ìœ ì§€

    # 1. ì˜¤ë¥˜ ì½”ë“œ ì¶”ì¶œ
    error_codes = re.findall(r'GPV\d{4}', text)
    unique_codes = sorted(set(error_codes))

    # 2. ì‹œìŠ¤í…œ ì´ë¦„ ì¶”ì¶œ
    systems = re.findall(r'(MRSS|UCEMS|NCRAB|MEIN|GTBS|BATCH|SICS|GHUB)', text)
    unique_systems = sorted(set(systems))

    # 3. ìš”ì•½ ë¬¸ì¥ ìƒì„±
    summary_parts = []
    if unique_codes:
        summary_parts.append(f"{len(unique_codes)}ê°œ ì˜¤ë¥˜ì½”ë“œ ê°ì§€ë¨ ({', '.join(unique_codes[:3])}...)")
    if unique_systems:
        summary_parts.append(f"ì—°ë™ ì‹œìŠ¤í…œ: {', '.join(unique_systems)}")

    return " / ".join(summary_parts) if summary_parts else "ì˜¤ë¥˜ ëª©ë¡ í¬í•¨"

def refine_descriptions(refined_json):
    for step in refined_json.get("steps", []):
        original = step.get("description", "")
        step["description"] = summarize_description(original)
    return refined_json

def refine_api_descriptions(parsed_json):
    for step in parsed_json.get("steps", []):
        action = step.get("action")
        if action:
            embedding = get_embedding(action)
            raw_description = search_description_by_embedding(embedding)
            summarized = summarize_description(raw_description)
            step["description"] = summarized
    # print("==== refine_api_descriptions ì™„ë£Œ ====")
    # print(parsed_json)
    return parsed_json


# í•¨ìˆ˜: PlantUML ìƒì„± í”„ë¡¬í”„íŠ¸ (ìˆ˜ì •ë³¸: PlantUML ì½”ë“œë§Œ ë°˜í™˜ ê°•ì œ)
def build_generate_prompt(refined_steps: Dict[str, Any]) -> List[Dict[str, str]]:
    """
    LLM Generate ë‹¨ê³„ì— ë„£ì„ í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ ìƒì„±
    - ë°˜ë“œì‹œ PlantUML ì½”ë“œ ë¸”ë¡ë§Œ ë°˜í™˜í•˜ë„ë¡ ê°•ì œ
    """
    return [
        {
            "role": "system",
            "content": (
                "ë‹¹ì‹ ì€ ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨(PlantUML) ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
                "ì¶œë ¥ì€ ë°˜ë“œì‹œ PlantUML ì½”ë“œ(@startuml ... @enduml)ë§Œ ë°˜í™˜í•´ì•¼ í•˜ë©°, "
                "ì„¤ëª…ì´ë‚˜ ì£¼ì„, JSON, ``` ì½”ë“œë¸”ë¡ ë“± ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤."
            )
        },
        {
            "role": "user",
            "content": f"""
ì•„ë˜ refined_stepsë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨ì„ PlantUML ì½”ë“œë¡œ ë³€í™˜í•˜ì‹œì˜¤.

ê·œì¹™:
- ê° ê³ ìœ  actor/participantëŠ” actor ë˜ëŠ” participantë¡œ ì„ ì–¸
- ê° í™”ì‚´í‘œ ë¼ë²¨ì— latency_ms í¬í•¨ (ì˜ˆ: "POST /subscribe\\n120ms")
- statusê°€ 4xx/5xxì¸ stepì€ í•´ë‹¹ í™”ì‚´í‘œ ë’¤ì— #red ìƒ‰ìƒ ì£¼ì„ ì¶”ê°€
- confidence ê°™ì€ ë©”íƒ€ ì •ë³´ëŠ” PlantUML ì£¼ì„("' ...")ìœ¼ë¡œë§Œ í‘œì‹œ
- IN-REQ, OUT-REQëŠ” í™”ì‚´í‘œ -> , IN-RES, OUT-RESëŠ” í™”ì‚´í‘œ --> ì‚¬ìš©.
- ì¶œë ¥ì€ ë°˜ë“œì‹œ @startuml ... @enduml ë¸”ë¡ë§Œ ë°˜í™˜

ì…ë ¥:
{json.dumps(refined_steps, ensure_ascii=False, indent=2)}

ì¶œë ¥ ì˜ˆì‹œ:
@startuml
actor "Skylife-API"
participant "PICASO-GW"
Skylife-API -> PICASO-GW : POST /subscribe\\n120ms
@enduml
"""
        }
    ]

# í•¨ìˆ˜: OpenAI í˜¸ì¶œ 
def call_openai(messages):
 
    response = openai_client.chat.completions.create(
        model=AZURE_DEPLOYMENT_MODEL,
        messages=messages,
        temperature=1.0,
        max_tokens=1500
    )
    # print(response.choices[0].message.content)
    return response.choices[0].message.content

def logs_to_plantuml(trace_logs: List[Dict[str, Any]]) -> str:
    """
    ë‹¨ì¼ íŠ¸ëœì­ì…˜ ë¡œê·¸(trace_logs)ë¥¼ ì…ë ¥ë°›ì•„
    1) Parse ë‹¨ê³„(JSON) â†’ 2) Generate ë‹¨ê³„(PlantUML)ê¹Œì§€ ì‹¤í–‰ í›„ PlantUML ì½”ë“œ ë°˜í™˜
    """
    # 1ë‹¨ê³„: Parse
    parse_prompt = build_parse_prompt(trace_logs)
    parsed_output = call_openai(parse_prompt)
    parsed_json = json.loads(parsed_output)
    # print("==== parsed_json ====")
    # print(parsed_json)

    # 1.5ë‹¨ê³„: Refine (API ì„¤ëª… ë³´ì™„) => ë³´ì™„í•„ìš”ë¡œ ì—°ê²° ì œê±°
    # refined_json = refine_api_descriptions(parsed_json)
    # print("==== refined_json ====")
    # print(refined_json)

    # 2ë‹¨ê³„: Generate
    generate_prompt = build_generate_prompt(parsed_json)
    # generate_prompt = build_generate_prompt(refined_json)
    plantuml_code = call_openai(generate_prompt)

    return plantuml_code

# Streamlit UI
st.set_page_config(layout="wide",page_title="ì‹œí€€ìŠ¤ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±", page_icon="ğŸ‡")
st.title("ğŸ“¡ PICASO ë¡œê·¸ ê¸°ë°˜ ì‹œí€€ìŠ¤ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±")

uploaded_file = st.file_uploader("ë¡œê·¸ íŒŒì¼ ì—…ë¡œë“œ", type=["json","log","txt"])
if uploaded_file:
    try:
        raw = json.load(uploaded_file)
        # ì‹¤ì œ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        hits = raw.get("hits", {}).get("hits", [])
        logs = [h["_source"] for h in hits if "_source" in h]

        # st.subheader("ğŸ“‚ ì „ì²˜ë¦¬ëœ ë¡œê·¸ ë¯¸ë¦¬ë³´ê¸°")
        # st.json(logs[:3])  # ì• 3ê°œë§Œ í™•ì¸

        # íŠ¸ëœì­ì…˜ ID ëª©ë¡ ì¶”ì¶œ
        trace_ids = list(set([log.get("transactionId") for log in logs if isinstance(log, dict)]))

        # ì¢Œ/ìš° ë ˆì´ì•„ì›ƒ
        col1, col2 = st.columns([1, 1])
        with col1:
            st.subheader("ğŸ” ì„ íƒëœ ë¡œê·¸")
            # í•­ìƒ ë‘ ì…ë ¥ UIë¥¼ ëª¨ë‘ ë³´ì—¬ì¤Œ
            manual_trace = st.text_input("ì§ì ‘ íŠ¸ëœì­ì…˜ ID ì…ë ¥", "")
            selected_from_list = st.selectbox("ë¶„ì„í•  íŠ¸ëœì­ì…˜ ì„ íƒ", trace_ids)

            # ìµœì¢… ì„ íƒ ë¡œì§
            if manual_trace.strip():
                if manual_trace.strip() in trace_ids:
                    selected_trace = manual_trace.strip()
                else:
                    st.warning("âš ï¸ ì…ë ¥í•œ íŠ¸ëœì­ì…˜ IDê°€ ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤. ì…€ë ‰íŠ¸ ë°•ìŠ¤ì—ì„œ ì„ íƒí•œ ê°’ì´ ì ìš©ë©ë‹ˆë‹¤.")
                    selected_trace = selected_from_list
            else:
                selected_trace = selected_from_list

            # ì„ íƒëœ íŠ¸ëœì­ì…˜ ë¡œê·¸ë§Œ í•„í„°ë§
            trace_logs = [log for log in logs if log.get("transactionId") == selected_trace]

            st.write(f"í˜„ì¬ ì„ íƒëœ íŠ¸ëœì­ì…˜ ID: **{selected_trace}**")
            st.json(trace_logs)

        with col2:
            st.subheader("âš™ï¸ ì‹œí€€ìŠ¤ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±")
            if st.button("ğŸš€ End-to-End ì‹¤í–‰"):
                with st.spinner("LLM ë¶„ì„ ë° ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì¤‘..."):
                    try:
                        plantuml_code = logs_to_plantuml(trace_logs)

                        st.subheader("ğŸ“ˆ ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨ ì½”ë“œ (PlantUML)")
                        st.code(plantuml_code, language="plantuml")

                        # PlantUML ì„œë²„ ë Œë”ë§ ë§í¬
                        encoded = plantuml.encode_plantuml(plantuml_code)
                        uml_url = f"http://www.plantuml.com/plantuml/svg/{encoded}"
                        st.image(uml_url)
                        st.markdown(f"[ğŸ–¼ï¸ ìƒˆì°½ì—ì„œ ë³´ê¸°]({uml_url})")

                    except Exception as e:
                        st.error(f"End-to-End ì‹¤í–‰ ì˜¤ë¥˜: {e}")

    except Exception as e:
        st.error(f"íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
        st.stop()


